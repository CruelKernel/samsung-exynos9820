#!/usr/bin/env python3

import os, errno
from sys import argv, stdout, stderr
import re
import json
from copy import deepcopy
from datetime import datetime, timedelta
from subprocess import CalledProcessError, Popen, run, DEVNULL, PIPE
from shutil import which
from enum import Enum, IntEnum
from collections import namedtuple
from struct import unpack_from, calcsize
from select import poll
from time import sleep
from timeit import default_timer as timer
from ctypes import CDLL, get_errno, c_int
from ctypes.util import find_library
from errno import EINTR
from termios import FIONREAD
from fcntl import ioctl
from io import FileIO
from os import fsencode, fsdecode


toolchain = {
    'default': {
        'CROSS_COMPILE': 'toolchain/gcc-cfp/gcc-cfp-jopp-only/aarch64-linux-android-4.9/bin/aarch64-linux-android-',
        'CLANG_TRIPLE': 'toolchain/clang/host/linux-x86/clang-4639204-cfp-jopp/bin/aarch64-linux-gnu-',
        'CC': 'toolchain/clang/host/linux-x86/clang-4639204-cfp-jopp/bin/clang'
    },
    'cruel': {
        'CROSS_COMPILE': 'toolchain/bin/aarch64-cruel-elf-'
    },
    'samsung': {
        'CROSS_COMPILE': 'toolchain/gcc-cfp/gcc-cfp-jopp-only/aarch64-linux-android-4.9/bin/aarch64-linux-android-',
        'CLANG_TRIPLE': 'toolchain/clang/host/linux-x86/clang-r349610-jopp/bin/aarch64-linux-gnu-',
        'CC': 'toolchain/clang/host/linux-x86/clang-r349610-jopp/bin/clang'
    },
    'proton': {
        'CROSS_COMPILE': 'toolchain/bin/aarch64-linux-gnu-',
        'CROSS_COMPILE_ARM32': 'toolchain/bin/arm-linux-gnueabi-',
        'CC': 'toolchain/bin/clang',
        'LD': 'toolchain/bin/ld.lld',
        'AR': 'toolchain/bin/llvm-ar',
        'NM': 'toolchain/bin/llvm-nm',
        'OBJCOPY': 'toolchain/bin/llvm-objcopy',
        'OBJDUMP': 'toolchain/bin/llvm-objdump',
        'READELF': 'toolchain/bin/llvm-readelf',
        'OBJSIZE': 'toolchain/bin/llvm-size',
        'STRIP': 'toolchain/bin/llvm-strip',
        'LDGOLD': 'toolchain/bin/aarch64-linux-gnu-ld.gold',
        'LLVM_AR': 'toolchain/bin/llvm-ar',
        'LLVM_DIS': 'toolchain/bin/llvm-dis'
    },
    'arter97': {
        'CROSS_COMPILE': 'toolchain/bin/aarch64-elf-'
    },
    'arm': {
        'CROSS_COMPILE': 'toolchain/bin/aarch64-none-elf-'
    },
    'system': {
        'CROSS_COMPILE': 'aarch64-linux-gnu-'
    }
}

models = {
    'G970F': {
        'config': 'exynos9820-beyond0lte_defconfig'
    },
    'G970N': {
        'config': 'exynos9820-beyond0lteks_defconfig'
    },
    'G973F': {
        'config': 'exynos9820-beyond1lte_defconfig'
    },
    'G975F': {
        'config': 'exynos9820-beyond2lte_defconfig'
    },
    'G975N': {
        'config': 'exynos9820-beyond2lteks_defconfig'
    },
    'G977B': {
        'config': 'exynos9820-beyondx_defconfig'
    },
    'N970F': {
        'config': 'exynos9820-d1_defconfig'
    },
    'N971N': {
        'config': 'exynos9820-d1xks_defconfig'
    },
    'N975F': {
        'config': 'exynos9820-d2s_defconfig'
    },
    'N976B': {
        'config': 'exynos9820-d2x_defconfig'
    },
    'N976N': {
        'config': 'exynos9820-d2xks_defconfig'
    }
}

OBJTREE_SIZE_GB = 3


_libc = None
def _libc_call(function, *args):
    """Wrapper which raises errors and retries on EINTR."""
    while True:
        rc = function(*args)
        if rc != -1:
            return rc
        errno = get_errno()
        if errno != EINTR:
            raise OSError(errno, os.strerror(errno))

Event = namedtuple('Event', ['wd', 'mask', 'cookie', 'name'])

_EVENT_FMT = 'iIII'
_EVENT_SIZE = calcsize(_EVENT_FMT)

class INotify(FileIO):
    fd = property(FileIO.fileno)
    inotify_raw_events = []
    topdir = 1
    paths = {}
    event_files = set()

    def __init__(self, inheritable=False, nonblocking=False):
        try:
            libc_so = find_library('c')
        except RuntimeError:
            libc_so = None
        global _libc; _libc = _libc or CDLL(libc_so or 'libc.so.6', use_errno=True)
        O_CLOEXEC = getattr(os, 'O_CLOEXEC', 0) # Only defined in Python 3.3+
        flags = (not inheritable) * O_CLOEXEC | bool(nonblocking) * os.O_NONBLOCK 
        FileIO.__init__(self, _libc_call(_libc.inotify_init1, flags), mode='rb')
        self._poller = poll()
        self._poller.register(self.fileno())

    def add_watch(self, path, mask):
        path = str(path) if hasattr(path, 'parts') else path
        wd = _libc_call(_libc.inotify_add_watch, self.fileno(), fsencode(path), mask)
        self.paths[wd] = path
        if path == '.':
            self.topdir = wd
        return wd

    def readraw(self, timeout=None, read_delay=None):
        data = self._readall()
        if not data and timeout != 0 and self._poller.poll(timeout):
            if read_delay is not None:
                sleep(read_delay / 1000.0)
            data = self._readall()
        return data

    def _readall(self):
        bytes_avail = c_int()
        ioctl(self, FIONREAD, bytes_avail)
        if not bytes_avail.value:
            return b''
        return os.read(self.fileno(), bytes_avail.value)

    def collect_events(self, timeout=1, read_delay=None):
        self.inotify_raw_events.append(self.readraw(timeout=timeout, read_delay=read_delay))

    @staticmethod
    def parse_events(data):
        pos = 0
        events = []
        while pos < len(data):
            wd, mask, cookie, namesize = unpack_from(_EVENT_FMT, data, pos)
            pos += _EVENT_SIZE + namesize
            name = data[pos - namesize : pos].split(b'\x00', 1)[0]
            events.append(Event(wd, mask, cookie, fsdecode(name)))
        return events

    def _gather_event_files(self):
        event_files = set()
        for data in self.inotify_raw_events:
            for event in self.parse_events(data):
                if event.wd != -1:
                    if event.wd == self.topdir:
                        event_files.add(event.name)
                    else:
                        event_files.add(os.path.join(self.paths[event.wd], event.name))
                else:
                    fatal("Missing events with +src_reduce, try to use j=1")
        inotify_raw_events = []
        self.event_files.update(event_files)

    def get_event_files(self):
        self.collect_events()
        self._gather_event_files()
        return self.event_files

    def run(self, args):
        with Popen(args, stdout=stdout, stderr=stderr) as proc:
            while proc.poll() is None:
                self.collect_events()
            if proc.returncode:
                exit(proc.returncode)
        self._gather_event_files()

class flags(IntEnum):
    OPEN = 0x00000020  #: File was opened
    Q_OVERFLOW = 0x00004000  #: Event queue overflowed
    ONLYDIR = 0x01000000  #: only watch the path if it is a directory
    EXCL_UNLINK = 0x04000000  #: exclude events on unlinked objects

inotify = INotify()
watch_flags = flags.OPEN | flags.EXCL_UNLINK | flags.ONLYDIR
unused_files = set()


def get_toolchain_cc(compiler):
    cc = ''
    if 'CC' in toolchain[compiler]:
        cc = toolchain[compiler]['CC']
    else:
        cc = toolchain[compiler]['CROSS_COMPILE'] + 'gcc'
    return cc

def mount_tmpfs(target, req_mem_gb):
    if not os.path.ismount(target):
        meminfo = dict((i.split()[0].rstrip(':'),int(i.split()[1])) for i in open('/proc/meminfo').readlines())
        av_mem_gb = int(meminfo['MemAvailable'] / 1024 ** 2)
        if av_mem_gb >= req_mem_gb + 2:
            ret = run(['sudo', '--non-interactive',
                       'mount', '-t', 'tmpfs', '-o', 'rw,noatime,size=' + str(req_mem_gb) + 'G', 'tmpfs', target])
            if ret.returncode != 0:
                print('BUILD: error mounting tmpfs on ' + target, file=stderr)
            else:
                print('BUILD: tmpfs is mounted on ' + target)
        else:
            print('BUILD: will not mount tmpfs on ' + target + ' size ' + str(av_mem_gb) + 'G < ' + str(req_mem_gb + 2) + 'G')
    else:
        print(target + ' is already used as mountpoint', file=stderr)

def umount_tmpfs(target):
    if os.path.ismount(target):
        ret = run(['sudo', '--non-interactive', 'umount', target])
        if ret.returncode != 0:
            print("BUILD: error unmounting " + target, file=stderr)
        else:
            print("BUILD: " + target + " unmounted")

def remove_files(*files):
    for f in files: 
        try:
            os.remove(f)
        except FileNotFoundError:
            pass

def del_dirs(src_dir):
    for dirpath, _, _ in os.walk(src_dir, topdown=False):
        try:
            os.rmdir(dirpath)
        except OSError:
            pass

def mkdir(dirname):
    try:
        os.mkdir(dirname)
    except FileExistsError:
        pass

def scandir(dirname):
    topdirs = set()
    topfiles = set()
    with os.scandir(dirname) as it:
        for entry in it:
            if entry.is_dir():
                topdirs.add(entry.name)
            else:
                topfiles.add(entry.name)
    return topdirs, topfiles

def tool_exists(name):
    return which(name) is not None

def get_cores_num():
    return len(os.sched_getaffinity(0))

def set_env(**env):
    for key, value in env.items():
        if key not in os.environ:
            os.environ[key] = value
        value = os.environ[key]
        print(key + ' = ' + value)

def fatal(*args, **kwargs):
    print(*args, file=stderr, **kwargs)
    exit(1)

def print_usage():
    msg = f"""
Usage: {argv[0]} <stage> model=<model> name=<name> [+-]<conf1> [+-]<conf2> ...

<stage>: required argument
Where <stage> can be one of: config, build, mkimg, flash, pack
(:build, :mkimg, :flash, :pack). Each next stage will run all
previous stages first. Prefix ':' means skip all previous
stages.

model=<model> required phone model name
Supported models: {list(models.keys())}
Use model=all to build all available kernels.

name=<name>: optional custom kernel name
Use this switch if you want to change the name in
your kernel.

toolchain=<compiler>: optional toolchain switch
Supported compilers: {list(toolchain.keys())}
By default the kernel is build with default toolchain.

os_patch_level=<date>: use patch date (YYYY-MM)
instead of default one from build.mkbootimg.<model>
file. For example: os_patch_level="2020-02"

O=dir will perform out of tree kernel build in dir.
The script will try to mount tmpfs in dir if there
is enough available memory.

[+-]<conf>: optional list of configuration switches.
Use prefix '+' to enable the configuration.
Use prefix '-' to disable the configuration.
You can see full list of switches and default ones in
kernel/configs/cruel*.conf directory.
"""
    print(msg)

def parse_stage():
    stages = []
    modes = ['config', 'build', 'mkimg', 'flash', 'pack']
    omodes = [':build', ':mkimg', ':flash', ':pack']
    all_modes = modes + omodes

    try:
        mode = argv[1]
        if mode not in all_modes:
            raise Exception

        if mode in omodes:
            stages = [mode[1:]]
        else:
            stages = modes[0:modes.index(mode)+1]
            if mode == 'pack':
                stages.remove('flash')
    except Exception:
        print_usage()
        fatal('Please, specify the mode from {}.'.format(all_modes))

    return stages

def find_configs():
    configs = { 'kernel': {}, 'order': [] }
    prefix_len = len('cruel')
    suffix_len = len('.conf')
    files = [f for f in os.listdir('kernel/configs/') if re.match('^cruel[+-]?.*\.conf$', f)]
    for f in files:
        if f == 'cruel.conf':
            continue
        name = f[prefix_len+1:]
        name = name[:-suffix_len]
        enabled = True if f[prefix_len:prefix_len+1] == '+' else False
        configs['kernel'][name] = {
            'path': os.path.join('kernel/configs', f),
            'enabled': enabled,
            'default': enabled
        }
        if enabled:
            configs['order'].append(name)
    return configs

def save_config(file, configs):
    conf = deepcopy(configs)
    with open(file, 'w') as fh:
        json.dump(conf, fh, sort_keys=True, indent=4)

def load_config(file):
    with open(file, 'r') as fh:
        return json.load(fh)

def switch_config(opt, enable, configs):
    if opt in configs['kernel']:
        configs['kernel'][opt]['enabled'] = enable
    else:
        fatal("Unknown config '{}'.".format(opt))

    if enable:
        if opt in configs['order']:
            configs['order'].remove(opt)
        configs['order'].append(opt)
    else:
        if opt in configs['order']:
            configs['order'].remove(opt)

def parse_args():
    configs = find_configs()

    for arg in argv[2:]:
        if arg.find('=') != -1:
            (key, value) = arg.split('=', 1)

            enable = None
            if key[0] == '-' or key[0] == '+':
                enable = True if key[0] == '+' else False
                key = key[1:]

            if key not in [ 'name',
                            'model',
                            'os_patch_level',
                            'toolchain',
                            'magisk',
                            'O' ]:
                fatal('Unknown config {}.'.format(key))

            if enable == None:
                if key == 'model':
                    if value == 'all':
                        value = list(models.keys())
                    else:
                        value = value.split(',')
                configs[key] = value
            else:
                switch_config(key, enable, configs)

            if not value:
                fatal('Please, use {}="<name>".'.format(key))
            elif key == 'model':
                for m in value:
                    if m not in models:
                        fatal('Unknown device model: ' + m)
            elif key == 'os_patch_level':
                try:
                    datetime.strptime(value, '%Y-%m')
                except Exception:
                    fatal('Please, use os_patch_level="YYYY-MM". For example: os_patch_level="2020-02"')
            elif key == 'toolchain':
                if value not in toolchain:
                    fatal('Unknown toolchain: ' + value)
            elif key == 'magisk':
                if value != 'canary' and not re.match('^v\d+\.\d+', value):
                    fatal('Unknown magisk version: ' + value + ' (example: canary, v20.4, v19.4, ...)')
                configs['kernel']['magisk']['version'] = value
        else:
            switch = arg[0:1]
            enable = True if switch == '+' else False
            opt = arg[1:]
            if switch not in ['+', '-']:
                fatal("Unknown switch '{0}'. Please, use '+{0}'/'-{0}' to enable/disable option.".format(arg))
            switch_config(opt, enable, configs)

    if 'model' not in configs:
        first_model = list(models.keys())[0]
        if len(models) == 1:
            configs['model'] = [ first_model ]
        else:
            print_usage()
            fatal('Please, use model="<model>". For example: model="{}"'.format(first_model))

    return configs

def setup_env(features, configs, model):
    set_env(ARCH='arm64', ANDROID_MAJOR_VERSION='q')
    if features['fake_config']:
        defconfig = os.path.join('arch/arm64/configs', models[model]['config'])
        set_env(KCONFIG_BUILTINCONFIG=defconfig)

def config_info(configs, model):
    if 'name' in configs:
        print('Name: ' + configs['name'])
    else:
        print('Name: CRUEL')

    print('Model: ' + model)

    conf_msg = []
    kernel_configs = configs['kernel']
    for key in configs['order']:
        if kernel_configs[key]['enabled']:
            conf_msg.append(key + ' (default: ' + ('On' if kernel_configs[key]['default'] else 'Off') + ')')
    if conf_msg:
        print('Configuration:')
        for i in conf_msg:
            print("\t" + i)
    else:
        print('Configuration: basic')

    if 'os_patch_level' in configs:
        print('OS Patch Level: ' + configs['os_patch_level'])
    else:
        with open('cruel/build.mkbootimg.' + model, 'r') as fh:
            for line in fh:
                (arg, val) = line.split('=', 1)
                val = val.rstrip()
                if arg == 'os_patch_level':
                    print('OS Patch Level: ' + val)
                    break

def config_name(name, configdir='.'):
    run(['scripts/config',
        '--file', os.path.join(configdir, '.config'),
        '--set-str', 'LOCALVERSION', '-' + name], check=True)

def config_model(model, configdir='.'):
    run(['scripts/config',
        '--file', os.path.join(configdir, '.config'),
        '--disable', 'CONFIG_MODEL_NONE',
        '--enable', 'CONFIG_MODEL_' + model], check=True)

def make_config(features, configs, model):
    objtree = configs.get('O', '.')
    args = ['scripts/kconfig/merge_config.sh', '-O', objtree,
            os.path.join('arch/arm64/configs', models[model]['config']),
            'kernel/configs/cruel.conf']

    kernel_configs = configs['kernel']
    for key in configs['order']:
        if kernel_configs[key]['enabled']:
            args.append(kernel_configs[key]['path'])

    inotify.run(args)

    if 'name' in configs:
        config_name(configs['name'], objtree)

    if features['dtb']:
        config_model(model, objtree)

def update_magisk(version):
    cmd = ['usr/magisk/update_magisk.sh']
    if version:
        cmd.append(version)
    run(cmd, check=True)
    with open('usr/magisk/magisk_version', 'r') as fh:
        print('Magisk Version: ' + fh.readline())

def switch_toolchain(compiler):
    cc = os.path.abspath(get_toolchain_cc(compiler))
    if cc.startswith(os.path.realpath('toolchain')):
        branch = run(['git', 'submodule', 'foreach', 'git', 'rev-parse', '--abbrev-ref', 'HEAD'],
                     check=True, stdout=PIPE).stdout.decode('utf-8').splitlines()[1]
        if not (tool_exists(cc) and compiler == branch):
            ret = run(['git', 'submodule', 'foreach', 'git', 'rev-parse', '--verify', '--quiet', compiler],
                      stdout=DEVNULL, stderr=DEVNULL)
            if ret.returncode != 0:
                try:
                    run(['git', 'submodule', 'foreach', 'git', 'branch', compiler, 'origin/' + compiler],
                        check=True, stdout=DEVNULL, stderr=DEVNULL)
                except CalledProcessError:
                    fatal("Can't checkout to toolchain: " + compiler)
            run(['git', 'submodule', 'foreach', 'git', 'checkout', compiler], check=True)

def build(compiler, threads=1, objtree='.'):
    env = {}

    if compiler == 'system':
        env = toolchain[compiler]
    else:
        env = { k: os.path.abspath(v) for k, v in toolchain[compiler].items() }

    if objtree != '.':
        env['O'] = objtree

    if tool_exists('pigz'):
        env['KGZIP']='pigz'
    if tool_exists('pbzip2'):
        env['KBZIP2']='pbzip2'

    inotify.run(['make',
                 '-j', str(threads),
                 *{ k + '=' + v for k, v in env.items() }])

def mkbootimg(os_patch_level, seadroid, config, output, **files):
    if tool_exists('mkbootimg'):
        print("Preparing {}...".format(output))
        for f in files.values():
            if not os.path.isfile(f):
                fatal("Can't find file '{}'.".format(f))
        args = ['mkbootimg']
        with open(config) as fh:
            for line in fh:
                (arg, val) = line.split('=', 1)
                if arg == 'os_patch_level' and os_patch_level:
                    val = os_patch_level
                else:
                    val = val.rstrip()
                args.extend(['--' + arg, val])
        for k, v in files.items():
            args.extend(['--' + k, v])
        args.extend(['--output', output])

        run(args, check=True)

        if seadroid:
            with open(output, 'ab') as img:
                img.write('SEANDROIDENFORCE'.encode('ascii'))
    else:
        fatal("Please, install 'mkbootimg'.")

def mkdtboimg(dtbdir, config, output):
    if tool_exists('mkdtboimg'):
        print("Preparing {}...".format(output))
        inotify.run(['mkdtboimg', 'cfg_create', '--dtb-dir=' + dtbdir, output, config])
    else:
        fatal("Please, install 'mkdtboimg'.")

def mkvbmeta(output):
    if tool_exists('avbtool'):
        print('Preparing vbmeta...')
        run(['avbtool', 'make_vbmeta_image', '--out', output], check=True)
    else:
        fatal("Please, install 'avbtool'.")

def mkaptar(boot, vbmeta):
    if tool_exists('tar') and tool_exists('md5sum') and tool_exists('lz4'):
        print('Preparing AP.tar.md5...')
        run(['lz4', '-m', '-f', '-B6', '--content-size', boot, vbmeta], check=True)
        run(['tar', '-H', 'ustar', '-c', '-f', 'AP.tar', boot + '.lz4', vbmeta + '.lz4'], check=True)
        run(['md5sum AP.tar >> AP.tar && mv AP.tar AP.tar.md5'], check=True, shell=True)
    else:
        fatal("Please, install 'tar', 'lz4' and 'md5sum'.")

def adb_wait_for_device():
    print('Waiting for the device...')
    run(['adb', 'wait-for-device'])

def heimdall_wait_for_device():
    print('Waiting for download mode...')
    run('until heimdall detect > /dev/null 2>&1; do sleep 1; done', shell=True)

def heimdall_in_download_mode():
    return run(['heimdall', 'detect'], stdout=DEVNULL, stderr=DEVNULL).returncode == 0

def heimdall_flash_images(imgs):
    args = ['heimdall', 'flash']
    for partition, image in imgs.items():
        args.extend(['--' + partition.upper(), image])
    run(args, check=True)

def adb_reboot_download():
    run(['adb', 'reboot', 'download'])

def adb_reboot():
    run(['adb', 'reboot'])

def adb_get_kernel_version():
    run(['adb', 'shell', 'cat', '/proc/version'])

def adb_uid():
    return int(run(['adb', 'shell', 'id', '-u'], stdout=PIPE, check=True).stdout.decode('utf-8'))

def adb_check_su():
    try:
        run(['adb', 'shell', 'command', '-v', 'su'], check=True)
        return True
    except CalledProcessError:
        return False

def flash(samsung=False, **imgs):
    if tool_exists('adb'):
        is_root = False
        try:
            if not (samsung and heimdall_in_download_mode()):
                adb_wait_for_device()
                is_root = (adb_uid() == 0) or adb_check_su()
        except (FileNotFoundError, CalledProcessError):
            pass

        if is_root:
            for part, img in imgs.items():
                run(['adb', 'push',
                    img, '/data/local/tmp'],
                    check=True)
                run(['adb', 'shell',
                    "su -c 'dd if=/data/local/tmp/" + img +
                             " of=/dev/block/by-name/" + part + "'"],
                    check=True)
                run(['adb', 'shell', 'rm', '-f', '/data/local/tmp/' + img])
            adb_reboot()
            adb_wait_for_device()
            adb_get_kernel_version()
        elif samsung and tool_exists('heimdall'):
            if not heimdall_in_download_mode():
                adb_wait_for_device()
                adb_reboot_download()
            heimdall_wait_for_device()
            heimdall_flash_images(imgs)
            adb_wait_for_device()
            adb_get_kernel_version()
        else:
            fatal("Please, use 'adb root' or install 'heimdall'")
    else:
        fatal("Please, install 'adb'")

def pack(images):
    if tool_exists('xz'):
        print('Preparing CruelKernel.tar.xz ...')
        set_env(XZ_OPT='-9')
        run(['tar', '-cJf', 'CruelKernel.tar.xz', *images], check=True)
    else:
        fatal("Please, install 'xz'.")

def detect_features(configs, features):
    for f in features:
        if f in configs['kernel'] and configs['kernel'][f]['enabled']:
            features[f] = True
    return features

if __name__ == '__main__':
    os.chdir(os.path.dirname(os.path.realpath(__file__)))

    configs = {}
    stages = parse_stage()
    device_models = None
    single_model = True
    objtree = '.'

    features = {
        'src_reduce': False,
        'magisk': False,
        'dtb': False,
        'fake_config': False,
        'samsung': False
    }

    if 'config' in stages:
        remove_files('config.json')

        configs = parse_args()
        features = detect_features(configs, features)
        save_config('config.json', configs)

        if 'O' in configs:
            objtree = configs['O']
            mkdir(objtree)
            mount_tmpfs(objtree, OBJTREE_SIZE_GB)
            run(['make', 'mrproper'])

        if features['src_reduce']:
            if 'O' not in configs:
                fatal('Please, use out of tree build with +src_reduce')

            inotify.add_watch('.', watch_flags)

            topdirs, unused_files = scandir('.')
            topdirs.remove('.git')
            topdirs.remove('toolchain')
            topdirs.remove('.github')
            topdirs.remove(objtree)
            unused_files.remove('cruelbuild')

            for dir in topdirs:
                for root, dirs, files in os.walk(dir, topdown=False):
                    unused_files.update({ os.path.join(root, f) for f in files })
                    for d in dirs:
                        inotify.add_watch(os.path.join(root, d), watch_flags)

        remove_files(os.path.join(objtree, '.config'))

        device_models = configs['model']
        if len(device_models) == 1:
            model = device_models[0]
            config_info(configs, model)
            setup_env(features, configs, model)
            make_config(features, configs, model)
    else:
        configs = load_config('config.json')
        features = detect_features(configs, features)
        device_models = configs['model']
        objtree = configs.get('O', '.')

    if len(device_models) > 1:
        single_model = False
        if len(stages) == 1 and (stages[0] == 'mkimg' or stages[0] == 'flash'):
            fatal("Please, don't use :mkimg with multiple models")

    compiler = configs.get('toolchain', 'default')
    if 'build' in stages:
        print('Toolchain: ' + compiler)
        switch_toolchain(compiler)

    build_time = 0
    for model in device_models:
        if 'build' in stages:
            print('Build date: ' + datetime.utcnow().strftime('%Y-%m-%d %H:%M UTC'))
            config_info(configs, model)
            setup_env(features, configs, model)
            if not os.path.exists(os.path.join(objtree, '.config')):
                make_config(features, configs, model)

            if features['magisk']:
                update_magisk(configs['kernel']['magisk'].get('version'))

            start = timer()
            build(compiler, get_cores_num(), objtree)
            build_time += timer() - start

            if not single_model:
                os.remove(os.path.join(objtree, '.config'))

        if 'mkimg' in stages:
            os_patch_level = ''
            if 'os_patch_level' in configs:
                os_patch_level = configs['os_patch_level']
            mkbootimg(os_patch_level,
                      features['samsung'],
                      'cruel/build.mkbootimg.' + model,
                      'CruelKernel-' + model + '.img',
                      kernel = os.path.join(objtree, 'arch/arm64/boot/Image'))
            if features['dtb']:
                mkdtboimg(os.path.join(objtree, 'arch/arm64/boot/dts/exynos'),
                          'cruel/dtb.' + model,
                          'CruelKernel-' + model + '-dtb.img')
                mkdtboimg(os.path.join(objtree, 'arch/arm64/boot/dts/samsung'),
                          'cruel/dtbo.' + model,
                          'CruelKernel-' + model + '-dtbo.img')
            #mkvbmeta('vbmeta.img')
            #mkaptar(boot_img, 'vbmeta.img')

    if single_model and 'flash' in stages:
        model = device_models[0]
        if features['dtb']:
            flash(features['samsung'],
                  boot = 'CruelKernel-' + model + '.img',
                  dtb  = 'CruelKernel-' + model + '-dtb.img',
                  dtbo = 'CruelKernel-' + model + '-dtbo.img')
        else:
            flash(features['samsung'],
                  boot = 'CruelKernel-' + model + '.img')

    if 'pack' in stages:
        images = []
        for m in device_models:
            images.append('CruelKernel-' + m + '.img')
            if features['dtb']:
                images.extend([ 'CruelKernel-' + m + '-dtb.img',
                                'CruelKernel-' + m + '-dtbo.img' ])
        pack(images)

    if 'mkimg' in stages:
        umount_tmpfs(objtree)

    if features['src_reduce']:
        unused_files -= inotify.get_event_files()
        remove_files(*unused_files)
        del_dirs('.')

    if build_time:
        print("Build time: " + str(timedelta(seconds=round(build_time))))
